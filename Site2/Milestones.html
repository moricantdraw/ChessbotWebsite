<!DOCTYPE html>
<html style="font-size: 16px;" lang="en"><head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="keywords" content="Milestone Reports ​, Milestone 1​, Milestone 2​">
    <meta name="description" content="">
    <title>Milestones</title>
    <link rel="stylesheet" href="nicepage.css" media="screen">
<link rel="stylesheet" href="Milestones.css" media="screen">
    <script class="u-script" type="text/javascript" src="jquery.js" defer=""></script>
    <script class="u-script" type="text/javascript" src="nicepage.js" defer=""></script>
    <meta name="generator" content="Nicepage 7.1.0, nicepage.com">
    <link id="u-theme-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i|Open+Sans:300,300i,400,400i,500,500i,600,600i,700,700i,800,800i">
    
    
    
    
    
    
    
    <script type="application/ld+json">{
		"@context": "http://schema.org",
		"@type": "Organization",
		"name": "",
		"logo": "images/3253587.png"
}</script>
    <meta name="theme-color" content="#478ac9">
    <meta property="og:title" content="Milestones">
    <meta property="og:type" content="website">
  <meta data-intl-tel-input-cdn-path="intlTelInput/"></head>
  <body data-path-to-root="./" data-include-products="false" class="u-body u-xl-mode" data-lang="en"><header class="u-clearfix u-grey-75 u-header" id="sec-2ca1" data-animation-name="" data-animation-duration="0" data-animation-delay="0" data-animation-direction=""><div class="u-clearfix u-sheet u-sheet-1">
        <a href="#" class="u-image u-logo u-image-1" data-image-width="128" data-image-height="128">
          <img src="images/3253587.png" class="u-logo-image u-logo-image-1">
        </a>
        <nav class="u-menu u-menu-one-level u-offcanvas u-menu-1">
          <div class="menu-collapse" style="font-size: 1rem; letter-spacing: 0px;">
            <a class="u-button-style u-custom-left-right-menu-spacing u-custom-padding-bottom u-custom-top-bottom-menu-spacing u-hamburger-link u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="#">
              <svg class="u-svg-link" viewBox="0 0 24 24"><use xlink:href="#menu-hamburger"></use></svg>
              <svg class="u-svg-content" version="1.1" id="menu-hamburger" viewBox="0 0 16 16" x="0px" y="0px" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><g><rect y="1" width="16" height="2"></rect><rect y="7" width="16" height="2"></rect><rect y="13" width="16" height="2"></rect>
</g></svg>
            </a>
          </div>
          <div class="u-nav-container">
            <ul class="u-nav u-unstyled u-nav-1"><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="./" style="padding: 10px 20px;">HomePage</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Key-Features.html" style="padding: 10px 20px;">Key Features</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Milestones.html" style="padding: 10px 20px;">Milestones</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Ethics-Statement.html" style="padding: 10px 20px;">Ethics Statement</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="Extras.html" style="padding: 10px 20px;">Extras</a>
</li></ul>
          </div>
          <div class="u-nav-container-collapse">
            <div class="u-black u-container-style u-inner-container-layout u-opacity u-opacity-95 u-sidenav">
              <div class="u-inner-container-layout u-sidenav-overflow">
                <div class="u-menu-close"></div>
                <ul class="u-align-center u-nav u-popupmenu-items u-unstyled u-nav-2"><li class="u-nav-item"><a class="u-button-style u-nav-link" href="./">HomePage</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Key-Features.html">Key Features</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Milestones.html">Milestones</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Ethics-Statement.html">Ethics Statement</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Extras.html">Extras</a>
</li></ul>
              </div>
            </div>
            <div class="u-black u-menu-overlay u-opacity u-opacity-70"></div>
          </div>
        </nav>
      </div></header>
    <section class="skrollable u-clearfix u-image u-parallax u-section-1" id="carousel_93d2" data-image-width="1280" data-image-height="853">
      <div class="u-clearfix u-sheet u-valign-middle u-sheet-1">
        <div class="u-container-align-center u-container-style u-group u-white u-group-1">
          <div class="u-container-layout u-container-layout-1">
            <h1 class="u-align-center u-text u-title u-text-1">Milestone Reports </h1>
            <p class="u-align-center u-text u-text-default u-text-2">This project was broken up into 3 project sprints.&nbsp; Between these sprints we completed two milestone report to track our progress. Below we have the reports archived&nbsp; &nbsp; </p>
          </div>
        </div>
      </div>
    </section>
    <section class="u-clearfix u-container-align-left u-grey-80 u-section-2" id="carousel_5cb1">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-align-left u-text u-text-1">Milestone 1 </h2>
        <p class="u-align-left u-text u-text-2">After about 1 week of working on the project our team was able to make progress on three major fronts:<br>
          <br>
          <span style="font-weight: 700;">#1 Computational Set-up&nbsp;</span>
          <br>In order to operate the Widow X with our computers we used the the robot bridge repository from Beverly Robot and AI laboratory.<br>
          <br>&nbsp;We were also able to get a functional simulator running for the Widow X on each of our computers using the Trossen robotics x series arms simulator. This will be invaluable for testing as we begin to write our own nodes and don’t all have access to the Widow X at the same times.<br>
          <br>&nbsp;We also started a collection of helpful commands for controlling the robot<br>
          <br>
          <span style="font-weight: 700;">#2 Background Research</span>&nbsp;<br>Before we started working on our node network we did some research on previous uses of the Widow X, previous chess bots and kinematic arm theory. We learned a lot about how package for the widow X can be structured, parallel vs forward kinematics arm theory and machine vision depth solutions that will inform how we structure our project.<br>
          <br>
          <span style="font-weight: 700;">#3 Structure Plan&nbsp;</span>
          <br>Our structure plan is the precursor of our system architecture that we will be finalizing in the next few days. It can be seen in greater detail below. While we were designing this we tried to keep in mind what the objective of the project was and how we could scope our MVP accordingly. For example, the objective of this project is not to estimate depth using stereo vision. Therefore for our MVP we are finding alternative ways of estimating a chess pieces pose in the three dimensional space.<br>
          <br> Though some of the finer details to this project have not yet been decided we have a much better idea of what kinds of problems we will have to solve and are excited to starting tackling them. <br>
          <br>
          <br>
          <span style="font-weight: 700;">Package Structure&nbsp;</span>
          <br>
          <br>We intend to structure our package in (at least) the following nodes <br>
          <br>1. Perception<br>
          <br> This node will intake information from the camera and use it to determine which pieces are stored in which squares. <br>
          <br>2. Movement calculator<br>
          <br> The information from the perception node can be used to recreate the board and calculate the robots next move. This decision will be made using discrete math taken from Eddie’s discrete final. The final decision of which piece to move will be sent to the path planner node. <br>
          <br>3. Path Planner<br>
          <br> Our set up will be using a specific chess board with a precise relationship to the Widow X arm.   This will allow us to store the pose information of each square of the board such that when a piece is placed on a board we have a pose estimate for where it is based on which square it’s in. We can then create way-points along it’s trajectory to guide it. <br>
          <br>4. Arm movement controller<br>
          <br> Based on the way-point the arm is at is at the arm movement controller will guide the Widow X to move towards the point and tighten and loosen it’s grip as necessary.<br>
        </p>
      </div>
    </section>
    <section class="u-clearfix u-grey-60 u-section-3" id="carousel_9b8b">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-align-left u-text u-text-1">Milestone 2 </h2>
        <p class="u-align-left u-text u-text-2">
          <span style="font-weight: 700;">Computational Setup&nbsp;<br>
          </span>At the end of Milestone 1, we had a computational setup that sometimes worked, but was extremely finicky and unpredictable. During this milestone, we were able to convert this setup into one that can run the same way every time.&nbsp;<br>
          <br>The main problem we were running into was that the repository we were following required a RealSense camera to properly run the server for the robot, but we were having issues properly configuring our camera while running our docker container. In order to solve this, we modified the code that ran the server and removed all camera topics (and any other code snippets that required them), and we are now planning to use a different (not RealSense) camera and read from it separately. This fix allowed us to finally start testing Python executable files on the physical robot.&nbsp;<br>
          <br>
          <br>
          <span style="font-weight: 700;">Pick and Place&nbsp;</span>
          <br>The library we used for our computational setup has several built-in&nbsp;<br>functions for moving the robot. There is a move() function, which&nbsp;<br>moves the end effector to a specified pose in Cartesian space (, y, z,&nbsp;<br>roll, pitch, yaw), a step_action() function, which moves the end effector&nbsp;<br>pose incrementally by the amounts specified, and a move_gripper()&nbsp;<br>function that opens and closes the gripper.&nbsp;<br>
          <br>Using the functions specified above were able to implement a basic&nbsp;<br>pick and place function on our robot. This function takes a start point,&nbsp;<br>end point, the height required to grasp the object, and the clearance&nbsp;<br>height required for the move, and the robot then picks up an object&nbsp;<br>located at the start point and places it at the end point. The function&nbsp;<br>also contains a parameter for the maximum allowable gripper width&nbsp;<br>for picking and placing things in tight spaces.&nbsp;<br>
          <br>
          <br>
          <span style="font-weight: 700;">Four Corners</span>
          <br>In addition to Pick-and-Place, we also wrote a script that would move the end effector to each of the four corners of the chess board. Our goal with this script was to make sure that the arm had the capability to move its end effector to all the positions on our physical chess board. <br>
          <br>
        </p>
        <div class="custom-expanded u-video u-video-contain u-video-1">
          <div class="embed-responsive embed-responsive-1">
            <iframe style="position: absolute;top: 0;left: 0;width: 100%;height: 100%;" class="embed-responsive-item" src="https://youtube.com/shorts/U2MqF-DxuLc?feature=share&amp;autoplay=1" data-autoplay="1" frameborder="0" allowfullscreen=""></iframe>
          </div>
        </div>
      </div>
    </section>
    <section class="u-clearfix u-container-align-left u-grey-60 u-section-4" id="carousel_0e7b">
      <div class="u-clearfix u-sheet u-sheet-1">
        <p class="u-align-left u-text u-text-1">Through initial testing with running files on the physical robot, we’ve been able to learn <br>
          <br>1. Interbotix Python API basic commands such as `move()` and `step_action()` <br> - We are all new to the Interbotix python libraries. After completing Pick-and-Place and Four-Corners, we now have a better idea of how we’ll configure the robot to move to each square. <br>2. Compatibility between arm’s gripper and chess pieces <br> - We were worried that the arm would struggle to pick up chess pieces due to their cylindrical shape and that the gripper would be too wide to pick up individual pieces. Nevertheless, in the video above, we demonstrated its ability to pick up pawns in between other pieces. <br>3. Limits of the arm with our physical chess board <br> - We were concerned that the physical arm wouldn’t be able to reach the tiles furthest from its base. We found out that when setting move commands, the positions of the furthest tiles would exceed the joint limits. To address this issue, we’ve raised the arm’s apparatus to overlap with the side of the chess board. Now, our end effector should be able to reach all possible positions on the chess board. <br>
          <br>
          <span style="font-weight: 700;">Simulator&nbsp;</span>
          <br>For the simulator with arm, we wanted to achieve live simulation both with and without the robot attached to the computer. We worked on the simulator as a fail-safe in case the team could not get the physical arm running and possibly for multiple people to be working on the arm at the same time.&nbsp;<br>
          <br>
          <span style="font-weight: 700;">
            <span style="font-weight: 400;">-</span>
            <span style="font-weight: 400;">-With Connected Arm</span>
          </span>&nbsp;<br>We were able to run the connected arm with the simulator with the instructions in a separate tab.<br>
          <br>The commands open up an RViz display with the arm connected and the command moves the arm when arm commands are inputted through the control panel on RViz.&nbsp;<br>
          <br>--Without Connected Arm&nbsp;<br>We were able to run the connected arm remotely without needing to connect with the arm with the following command:&nbsp;<br>
          <br>ros2 launch interbotix_xsarm_control xsarm_control.launch.py robot_model:=wx200 use_sim:=true&nbsp;<br>
          <br>However, since we have the MVP for the physical WidowX bot working, we have decided to move away from using the simulator and using the physical bot.&nbsp;<br>
          <br>
        </p>
      </div>
    </section>
    <section class="u-clearfix u-grey-60 u-section-5" id="sec-eec8">
      <div class="u-clearfix u-sheet u-sheet-1">
        <p class="u-text u-text-default u-text-1">
          <span style="font-weight: 700;">AprilTags&nbsp;</span>
          <br>We also began working on detecting april tags and determining their positions using the python apriltag library. We wrote a script able to detect multiple april tags from a camera feed and get their IDs and position in the image. On the left is a screenshot of the output video feed, which outlines and IDs each april tag. On the right is part of the terminal output with the location of one of the tags, including the position of its center and corners. This information is printed about each tag and is constantly updating with their live positions.<br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <span style="font-weight: 700;">Kinematic Math<br>
          </span>Even though the kinematic math was abstracted by the Inter box API we still developed the flowing blog post that explains how the WidowX works. We felt that it was important to understand what was going on behind the scenes even if were weren’t manually completing the calculations. ​We therefore went through all of the math and how it's abstracted by the API<br>
          <br>
          <br>
          <span style="font-weight: 700;">Looking forward!</span>&nbsp;<br>Though we made good progress in the latest sprint we still have a ways to go! In order to make sure we stay on track we decided to break our remaining tasks into MVP task and stretch tasks.
For our MVP we would like to accomplish the following: <br>- Get everyone computationally set up<br>- Camera module<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;- Figure out where we want to put april tags (on pieces? chessboard corners?)<br>- MVP: 8x8 array of robot arm poses for each square<br>- MVP: pickup heights for each piece<br>- MVP(?): figure out how to pick up pieces on very corners of board without arm collapsing<br>- MVP: GUI to integrate chess engine&nbsp;<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - convert engine move to physical move<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - figure out which move the opponent made<br>
          <br> In our MVP our robot would only be using the camera to identify the opponents move. The robot would then calculate it’s move and execute it by going to pre-saved poses.&nbsp;<br>
          <br>For our stretch goals we would like to look at the following:&nbsp;<br>- April tags on edge of board to get a geometric map of the chess board (known distances between each square, pieces can be abstracted to the center point of each square)<br>- array of poses for graveyard<br>- figure out how to read move status from server so we dont’ have to do janky time.sleep stuff<br>-&nbsp; Camera
[ ]  select which camera we’re using<br>-&nbsp; Post-MVP
[ ]  mounting location for the camera<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; -&nbsp; physical camera mount design/fab(?)<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - functional AprilTag code in Python: geometric poses between april tags (on 4 corners of chess board) relative to camera<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;- AprilTag code for transforming camera frame to arm frame<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - post post post mvp: finger detection<br>
          <br>
          <br> In this implantation we could dig more into the machine vision aspect of the project: not only analyzing with machine vision but also finding more elegant, and sensor based methods of localization.&nbsp;<br>
          <br>As we go into the next week Mia and Dan will be working on the GUI Eddie will be working on the pose array, Kate will continue working with April tags and and Will will be working on the literal edge cases of the chess words. We plan to have our MVP completed by Wednesday so that we have time to give some of our undivided  a host and work on our website.&nbsp;<br>
          <br>
        </p>
        <img class="u-image u-image-default u-image-1" src="images/image7.png" alt="" data-image-width="697" data-image-height="418">
        <img class="u-image u-image-default u-image-2" src="images/image8.png" alt="" data-image-width="333" data-image-height="206">
      </div>
    </section>
    
    
    
    <footer class="u-align-center u-clearfix u-container-align-center u-footer u-grey-80 u-footer" id="sec-f3cd"><div class="u-clearfix u-sheet u-sheet-1"></div></footer>
    <section class="u-backlink u-clearfix u-grey-80">
      <p class="u-text">
        <span>This site was created with the </span>
        <a class="u-link" href="https://nicepage.com/" target="_blank" rel="nofollow">
          <span>Nicepage</span>
        </a>
      </p>
    </section>
  
</body></html>